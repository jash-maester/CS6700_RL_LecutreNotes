Let me first give a bit general introduction to Reinforcement Learning in general and how it came into the picture. This section is totally off-topic and won't aid in academics in any means but fun stuff to know nevertheless.

\begin{itemize}[leftmargin=*]
    \item Machine Learning primarily learns functions from into to output data. An over-simplified statement nevertheless.
    \item But imagine how you learnt to cycle?
    \begin{itemize}
        \item Surely by trial and error.
        \item Falling down surely hurt you --- Negative Reward.
        \item You learnt from your mistakes --- Evaluation, not an instruction.
        \item That is Reinforcement Learning --- in a nutshell.
    \end{itemize}
    \item In the domain of RL, we deal with trial-and-error learning paradigms mainly, else we need to frame our environment into a similar paradigm.
    \begin{itemize}
        \item Primary feedback to the Agent is essentially Rewards or Punishment (but we call it Negative Rewards).
    \end{itemize}
    \item The Agent learns through a system of interactions with the environment.
    \item RL was initially heavily inspired by behavioural psychology, and Control Theory.
    \begin{itemize}
        \item Eg: Pavlov's Dog Experiment.
    \end{itemize}
    \item Popular Works on RL can be seen nowadays on literally each an every tech blog, forums, articles, saying RL will change the world --- Rest assured, RL has infact made the life of some major professions easier.
    \begin{itemize}
        \item \textbf{Alpha-Fold}: Protein-Folding Problem.
        \item \textbf{Alpha-Go}: RL Agent beating human player miserably.
        \item \textbf{Upside-Down Helicopter}: I mean there is no practical need, but ``Hey! Andrew Ng did that''.
        \item Humanoid Movements.
        \item Path Planning Problems of classical robotics.
        \item Learning from occasional Human feedback --- Human in the Loop.
        \item Recommendation systems and so on and so forth.
    \end{itemize}
\end{itemize}

\input{chapters/Decision_Process.tex}